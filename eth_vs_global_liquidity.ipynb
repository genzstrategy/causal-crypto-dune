{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0dd0164-5a4f-4264-9c14-800727b72537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run to install \n",
    "\n",
    "#!pip install yfinance \n",
    "#!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9a82c9d-79e2-46b1-9ade-da5efad49c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de9ee387-3c25-4e0d-b227-cbd6b8d00b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = \"1d\"\n",
    "start_time = \"2018-01-01\"\n",
    "end_time = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')  # Set end_time to yesterday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22b191-afa6-4b08-b0e8-0f76cf33e520",
   "metadata": {},
   "source": [
    "1. **TLT (iShares 20+ Year Treasury Bond ETF)**: Invests in U.S. Treasury bonds with remaining maturities greater than 20 years, aiming to track the investment results of an index composed of U.S. Treasury bonds.\n",
    "\n",
    "2. **IEF (iShares 7-10 Year Treasury Bond ETF)**: Seeks to track the investment results of an index composed of U.S. Treasury bonds with remaining maturities between 7 and 10 years.\n",
    "\n",
    "3. **EZU (iShares MSCI Eurozone ETF)**: Provides exposure to large and mid-sized companies in Eurozone countries, tracking the MSCI EMU Index.\n",
    "\n",
    "4. **CNYA (iShares MSCI China A ETF)**: Offers exposure to large and mid-cap Chinese equities in the A-shares market, tracking the MSCI China A Inclusion Index.\n",
    "\n",
    "5. **EWJ (iShares MSCI Japan ETF)**: Tracks the investment results of an index composed of Japanese equities, representing large and mid-sized companies in Japan.\n",
    "\n",
    "6. **IGLT.L (iShares Core UK Gilts UCITS ETF)**: Invests in UK government bonds (gilts), seeking to track the performance of an index composed of sterling-denominated UK government bonds.\n",
    "\n",
    "7. **XBB.TO (iShares Core Canadian Universe Bond Index ETF)**: Offers exposure to Canadian government and corporate bonds, tracking the performance of the broad Canadian bond market.\n",
    "\n",
    "8. **BOND.AX (PIMCO Australian Bond Index Fund)**: Provides diversified exposure to the Australian bond market, including government, semi-government, and corporate debt securities.\n",
    "\n",
    "9. **INDA (iShares MSCI India ETF)**: Aims to track the investment results of an index composed of Indian equities, representing large and mid-sized companies in India.\n",
    "\n",
    "10. **EWL (iShares MSCI Switzerland ETF)**: Tracks the investment results of an index composed of Swiss equities, representing the Swiss stock market.\n",
    "\n",
    "11. **ERUS (iShares MSCI Russia ETF)**: Seeks to track the investment results of an index composed of Russian equities.\n",
    "\n",
    "12. **EWZ (iShares MSCI Brazil ETF)**: Aims to track the investment results of an index composed of Brazilian equities, reflecting the performance of the Brazilian stock market.\n",
    "\n",
    "13. **EWY (iShares MSCI South Korea ETF)**: Tracks the investment results of an index composed of South Korean equities, representing the South Korean stock market.\n",
    "\n",
    "14. **ENZL (iShares MSCI New Zealand ETF)**: Seeks to track the investment results of an index composed of New Zealand equities.\n",
    "\n",
    "15. **EWD (iShares MSCI Sweden ETF)**: Aims to track the investment results of an index composed of Swedish equities, representing the Swedish stock market.\n",
    "\n",
    "16. **EWM (iShares MSCI Malaysia ETF)**: Seeks to track the investment results of an index composed of Malaysian equities, representing the Malaysian stock market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4b3632-bd34-4c71-a64f-dfa778d07b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TLT': 0.4062292647451769, 'IEF': 0.21725878580669125, 'EZU': 0.055852416978285045, 'CNYA': 0.0015059291660515857, 'EWJ': 0.1100509895246457, 'IGLT.L': 0.0, 'XBB.TO': 0.05079602331873081, 'BOND.AX': 0.00028976165698744034, 'INDA': 0.06216563494820313, 'EWL': 0.010017395366789108, 'ERUS': 3.5989277115003057e-06, 'EWZ': 0.04721188425186288, 'EWY': 0.03323243466653609, 'ENZL': 0.0008995802005002043, 'EWD': 0.0026062376516634176, 'EWM': 0.0018800627901649591}\n"
     ]
    }
   ],
   "source": [
    "# Define ETFs\n",
    "etfs = [\"TLT\", \"IEF\", \"EZU\", \"CNYA\", \"EWJ\", \"IGLT.L\", \"XBB.TO\", \"BOND.AX\", \"INDA\", \"EWL\", \"ERUS\", \"EWZ\", \"EWY\", \"ENZL\", \"EWD\", \"EWM\"]\n",
    "\n",
    "# Fetch ETF data\n",
    "etf_data = {etf: yf.Ticker(etf).info for etf in etfs}\n",
    "\n",
    "# Retrieve AUM or market cap\n",
    "aum = {etf: data.get('totalAssets', 0) for etf, data in etf_data.items()}  \n",
    "\n",
    "# Calculate total AUM\n",
    "total_aum = sum(aum.values())\n",
    "\n",
    "# Calculate weightings\n",
    "weights = {etf: value / total_aum for etf, value in aum.items()}\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad21236-0277-4f8b-8491-9acfb4ae8fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "NaN count per column:\n",
      " ^IRX                       0\n",
      "^TNX                       0\n",
      "^TYX                       0\n",
      "SPY                        0\n",
      "QQQ                        0\n",
      "TLT                        0\n",
      "IEF                        0\n",
      "EZU                        0\n",
      "CNYA                       0\n",
      "EWJ                        0\n",
      "IGLT.L                    30\n",
      "XBB.TO                    32\n",
      "BOND.AX                   31\n",
      "INDA                       0\n",
      "EWL                        0\n",
      "ERUS                       0\n",
      "EWZ                        0\n",
      "EWY                        0\n",
      "ENZL                       0\n",
      "EWD                        0\n",
      "EWM                        0\n",
      "ETH-USD                    0\n",
      "Global_Liquidity_Index     0\n",
      "dtype: int64\n",
      "Total NaN values in the DataFrame: 93\n"
     ]
    }
   ],
   "source": [
    "# Existing tickers and ETF tickers (& BTC, ETH in USD)\n",
    "tickers = [\"^IRX\", \"^TNX\", \"^TYX\", \"SPY\", \"QQQ\"]\n",
    "etf_tickers = etfs  \n",
    "tickers.extend(etf_tickers)\n",
    "crypto_tickers = ['ETH-USD']\n",
    "tickers.extend(crypto_tickers)\n",
    "\n",
    "# Retrieve historical data\n",
    "historical_data = {}\n",
    "for ticker in tickers:\n",
    "    historical_data[ticker] = yf.download(ticker, start=start_time, end=end_time, interval=frequency)['Close']\n",
    "\n",
    "# Combine and weight data\n",
    "combined_data = pd.DataFrame()\n",
    "for ticker, data in historical_data.items():\n",
    "    if ticker in weights:  # Check if ticker is in ETFs list\n",
    "        combined_data[ticker] = data * weights[ticker]\n",
    "    else:  # Use the data as is for other tickers\n",
    "        combined_data[ticker] = data\n",
    "\n",
    "# Calculate the Global Liquidity Index as the sum of all (weighted and non-weighted) columns, excluding crypto tickers\n",
    "combined_data['Global_Liquidity_Index'] = combined_data.drop(columns=crypto_tickers, errors='ignore').sum(axis=1)\n",
    "\n",
    "# Count NaN values in each column\n",
    "nan_count_per_column = combined_data.isna().sum()\n",
    "print(\"NaN count per column:\\n\", nan_count_per_column)\n",
    "\n",
    "# Total NaN values in the DataFrame\n",
    "total_nan_count = combined_data.isna().sum().sum()\n",
    "print(\"Total NaN values in the DataFrame:\", total_nan_count)\n",
    "\n",
    "combined_data.dropna(inplace=True)\n",
    "\n",
    "# combined_data now contains the weighted Global Liquidity Index and individual ticker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65dfa516-23c0-4d6f-a77c-e7a3549f2330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_Liquidity_Index</th>\n",
       "      <th>SPY</th>\n",
       "      <th>ETH-USD</th>\n",
       "      <th>GLI_diff</th>\n",
       "      <th>SPY_diff</th>\n",
       "      <th>ETH_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>529.356207</td>\n",
       "      <td>270.470001</td>\n",
       "      <td>962.719971</td>\n",
       "      <td>3.621430</td>\n",
       "      <td>1.700012</td>\n",
       "      <td>78.276001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>530.892631</td>\n",
       "      <td>271.609985</td>\n",
       "      <td>980.921997</td>\n",
       "      <td>1.536424</td>\n",
       "      <td>1.139984</td>\n",
       "      <td>18.202026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>534.315815</td>\n",
       "      <td>273.420013</td>\n",
       "      <td>997.719971</td>\n",
       "      <td>3.423184</td>\n",
       "      <td>1.810028</td>\n",
       "      <td>16.797974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>535.440183</td>\n",
       "      <td>273.920013</td>\n",
       "      <td>1148.530029</td>\n",
       "      <td>1.124368</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>150.810059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>535.429020</td>\n",
       "      <td>274.540009</td>\n",
       "      <td>1299.739990</td>\n",
       "      <td>-0.011163</td>\n",
       "      <td>0.619995</td>\n",
       "      <td>151.209961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>981.566617</td>\n",
       "      <td>476.510010</td>\n",
       "      <td>2378.739990</td>\n",
       "      <td>6.964180</td>\n",
       "      <td>2.860016</td>\n",
       "      <td>52.215088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>981.310051</td>\n",
       "      <td>476.690002</td>\n",
       "      <td>2347.566162</td>\n",
       "      <td>-0.256566</td>\n",
       "      <td>0.179993</td>\n",
       "      <td>-31.173828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>977.724911</td>\n",
       "      <td>475.309998</td>\n",
       "      <td>2300.690674</td>\n",
       "      <td>-3.585140</td>\n",
       "      <td>-1.380005</td>\n",
       "      <td>-46.875488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>967.824549</td>\n",
       "      <td>472.649994</td>\n",
       "      <td>2355.836426</td>\n",
       "      <td>-9.900362</td>\n",
       "      <td>-2.660004</td>\n",
       "      <td>55.145752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>959.748429</td>\n",
       "      <td>468.790009</td>\n",
       "      <td>2210.761963</td>\n",
       "      <td>-8.076120</td>\n",
       "      <td>-3.859985</td>\n",
       "      <td>-145.074463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1439 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Global_Liquidity_Index         SPY      ETH-USD  GLI_diff  \\\n",
       "Date                                                                    \n",
       "2018-01-03              529.356207  270.470001   962.719971  3.621430   \n",
       "2018-01-04              530.892631  271.609985   980.921997  1.536424   \n",
       "2018-01-05              534.315815  273.420013   997.719971  3.423184   \n",
       "2018-01-08              535.440183  273.920013  1148.530029  1.124368   \n",
       "2018-01-09              535.429020  274.540009  1299.739990 -0.011163   \n",
       "...                            ...         ...          ...       ...   \n",
       "2023-12-27              981.566617  476.510010  2378.739990  6.964180   \n",
       "2023-12-28              981.310051  476.690002  2347.566162 -0.256566   \n",
       "2023-12-29              977.724911  475.309998  2300.690674 -3.585140   \n",
       "2024-01-02              967.824549  472.649994  2355.836426 -9.900362   \n",
       "2024-01-03              959.748429  468.790009  2210.761963 -8.076120   \n",
       "\n",
       "            SPY_diff    ETH_diff  \n",
       "Date                              \n",
       "2018-01-03  1.700012   78.276001  \n",
       "2018-01-04  1.139984   18.202026  \n",
       "2018-01-05  1.810028   16.797974  \n",
       "2018-01-08  0.500000  150.810059  \n",
       "2018-01-09  0.619995  151.209961  \n",
       "...              ...         ...  \n",
       "2023-12-27  2.860016   52.215088  \n",
       "2023-12-28  0.179993  -31.173828  \n",
       "2023-12-29 -1.380005  -46.875488  \n",
       "2024-01-02 -2.660004   55.145752  \n",
       "2024-01-03 -3.859985 -145.074463  \n",
       "\n",
       "[1439 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = combined_data[['Global_Liquidity_Index', 'SPY', 'ETH-USD']].copy() # truncate df for dune upload\n",
    "\n",
    "# Calculate the first difference for the specified columns\n",
    "df['GLI_diff'] = df['Global_Liquidity_Index'].diff()\n",
    "df['SPY_diff'] = df['SPY'].diff()\n",
    "df['ETH_diff'] = df['ETH-USD'].diff()\n",
    "\n",
    "df.dropna(inplace=True) # drop missing value from first differencing  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "166b9ab0-19e8-4a46-bd88-2cfb453585e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('eth_global_liquidity_index.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ea35ce8-a491-42dd-9d50-0d1a7ade5396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for stationarity in series: Global_Liquidity_Index\n",
      "ADF Statistic: -0.870077\n",
      "p-value: 0.797667\n",
      "Critical Values:\n",
      "\t1%: -3.435\n",
      "\t5%: -2.864\n",
      "\t10%: -2.568\n",
      "The series Global_Liquidity_Index is likely non-stationary (fail to reject H0)\n",
      "\n",
      "___________________________________________________________________\n",
      "Testing for stationarity in series: SPY\n",
      "ADF Statistic: -0.911177\n",
      "p-value: 0.784269\n",
      "Critical Values:\n",
      "\t1%: -3.435\n",
      "\t5%: -2.864\n",
      "\t10%: -2.568\n",
      "The series SPY is likely non-stationary (fail to reject H0)\n",
      "\n",
      "___________________________________________________________________\n",
      "Testing for stationarity in series: ETH-USD\n",
      "ADF Statistic: -1.609237\n",
      "p-value: 0.478952\n",
      "Critical Values:\n",
      "\t1%: -3.435\n",
      "\t5%: -2.864\n",
      "\t10%: -2.568\n",
      "The series ETH-USD is likely non-stationary (fail to reject H0)\n",
      "\n",
      "___________________________________________________________________\n",
      "Testing for stationarity in series: GLI_diff\n",
      "ADF Statistic: -11.942660\n",
      "p-value: 0.000000\n",
      "Critical Values:\n",
      "\t1%: -3.435\n",
      "\t5%: -2.864\n",
      "\t10%: -2.568\n",
      "The series GLI_diff is likely stationary (reject H0)\n",
      "\n",
      "___________________________________________________________________\n",
      "Testing for stationarity in series: SPY_diff\n",
      "ADF Statistic: -11.928463\n",
      "p-value: 0.000000\n",
      "Critical Values:\n",
      "\t1%: -3.435\n",
      "\t5%: -2.864\n",
      "\t10%: -2.568\n",
      "The series SPY_diff is likely stationary (reject H0)\n",
      "\n",
      "___________________________________________________________________\n",
      "Testing for stationarity in series: ETH_diff\n",
      "ADF Statistic: -7.144617\n",
      "p-value: 0.000000\n",
      "Critical Values:\n",
      "\t1%: -3.435\n",
      "\t5%: -2.864\n",
      "\t10%: -2.568\n",
      "The series ETH_diff is likely stationary (reject H0)\n",
      "\n",
      "___________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    # Perform Augmented Dickey-Fuller test:\n",
    "    print(f'Testing for stationarity in series: {column}')\n",
    "    result = adfuller(df[column].dropna())  # dropna() handles missing values\n",
    "    print('ADF Statistic: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "    # Interpretation\n",
    "    if result[1] > 0.05:\n",
    "        print(f\"The series {column} is likely non-stationary (fail to reject H0)\\n\")\n",
    "        print(\"___________________________________________________________________\")\n",
    "    else:\n",
    "        print(f\"The series {column} is likely stationary (reject H0)\\n\")\n",
    "        print(\"___________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b59039-3856-46a7-b3a5-5020d7d551fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca9ac7f6-5cd0-472e-8b5f-333b66b8207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7f77693-cd6b-4fa2-bacb-11cc7425a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlations(ts1, ts2):\n",
    "    \"\"\"\n",
    "    Calculate the Pearson, Spearman, and Kendall Tau correlation coefficients along with their p-values for two time series.\n",
    "\n",
    "    Parameters:\n",
    "    ts1 : Pandas Series\n",
    "        The first time series.\n",
    "    ts2 : Pandas Series\n",
    "        The second time series.\n",
    "\n",
    "    Returns:\n",
    "    dict\n",
    "        A dictionary containing the Pearson, Spearman, and Kendall Tau correlation coefficients and their p-values.\n",
    "    \"\"\"\n",
    "    pearson_corr, pearson_p = pearsonr(ts1, ts2)\n",
    "    spearman_corr, spearman_p = spearmanr(ts1, ts2)\n",
    "    kendall_corr, kendall_p = kendalltau(ts1, ts2)\n",
    "\n",
    "    return {\n",
    "        'Pearson': {'Coefficient': pearson_corr, 'P-Value': pearson_p},\n",
    "        'Spearman': {'Coefficient': spearman_corr, 'P-Value': spearman_p},\n",
    "        'Kendall Tau': {'Coefficient': kendall_corr, 'P-Value': kendall_p}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb23b3cb-54e0-419f-b4b3-65fba1238f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pearson': {'Coefficient': 0.8536303299738879, 'P-Value': 0.0},\n",
       " 'Spearman': {'Coefficient': 0.853231414729038, 'P-Value': 0.0},\n",
       " 'Kendall Tau': {'Coefficient': 0.6608060187060053,\n",
       "  'P-Value': 1.167532715211163e-308}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gli_eth_corr = calculate_correlations(corr_df['Global_Liquidity_Index'], corr_df['ETH-USD'])\n",
    "gli_eth_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71618081-903c-49d1-b96f-3355d0393219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pearson': {'Coefficient': 0.2728260206791386,\n",
       "  'P-Value': 5.588229272732466e-26},\n",
       " 'Spearman': {'Coefficient': 0.27605847906020864,\n",
       "  'P-Value': 1.39160228141314e-26},\n",
       " 'Kendall Tau': {'Coefficient': 0.1889805256122655,\n",
       "  'P-Value': 6.592866680905039e-27}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i0_gli_eth_corr = calculate_correlations(corr_df['GLI_diff'], corr_df['ETH_diff'])\n",
    "i0_gli_eth_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0ecc719-3eae-43ec-9c37-5a21d6802523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pearson': {'Coefficient': 0.9894756608457902, 'P-Value': 0.0},\n",
       " 'Spearman': {'Coefficient': 0.989543352183409, 'P-Value': 0.0},\n",
       " 'Kendall Tau': {'Coefficient': 0.9228492657878836, 'P-Value': 0.0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gli_spy_corr = calculate_correlations(corr_df['Global_Liquidity_Index'], corr_df['SPY'])\n",
    "gli_spy_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "492655af-a1d8-4efb-9d71-fe7413dc871a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pearson': {'Coefficient': 0.9762339133756012, 'P-Value': 0.0},\n",
       " 'Spearman': {'Coefficient': 0.970570608216953, 'P-Value': 0.0},\n",
       " 'Kendall Tau': {'Coefficient': 0.8629422323690891, 'P-Value': 0.0}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i0_gli_spy_corr = calculate_correlations(corr_df['GLI_diff'], corr_df['SPY_diff'])\n",
    "i0_gli_spy_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a799887-2ecc-4903-b913-a3ed00f10295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_series_pairs</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Spearman</th>\n",
       "      <th>Kendall Tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GLI-ETH</td>\n",
       "      <td>0.853630</td>\n",
       "      <td>0.853231</td>\n",
       "      <td>0.660806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I0 GLI-ETH</td>\n",
       "      <td>0.272826</td>\n",
       "      <td>0.276058</td>\n",
       "      <td>0.188981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GLI-SPY</td>\n",
       "      <td>0.989476</td>\n",
       "      <td>0.989543</td>\n",
       "      <td>0.922849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I0 GLI-SPY</td>\n",
       "      <td>0.976234</td>\n",
       "      <td>0.970571</td>\n",
       "      <td>0.862942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  time_series_pairs   Pearson  Spearman  Kendall Tau\n",
       "0           GLI-ETH  0.853630  0.853231     0.660806\n",
       "1        I0 GLI-ETH  0.272826  0.276058     0.188981\n",
       "2           GLI-SPY  0.989476  0.989543     0.922849\n",
       "3        I0 GLI-SPY  0.976234  0.970571     0.862942"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_correlation_dataframe(dicts, names):\n",
    "    \"\"\"\n",
    "    Create a pandas DataFrame from a list of dictionaries containing correlation coefficients, with named rows.\n",
    "\n",
    "    Parameters:\n",
    "    dicts : list of dict\n",
    "        List of dictionaries with correlation data.\n",
    "    names : list of str\n",
    "        List of names for each time series pair.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame\n",
    "        A DataFrame with correlation coefficients and named rows.\n",
    "    \"\"\"\n",
    "    # Prepare data for DataFrame\n",
    "    data = {name: {metric: d[metric]['Coefficient'] for metric in ['Pearson', 'Spearman', 'Kendall Tau']} for name, d in zip(names, dicts)}\n",
    "\n",
    "    # Create DataFrame from the data\n",
    "    corr_df = pd.DataFrame(data).T\n",
    "\n",
    "    return corr_df\n",
    "\n",
    "# Names for each time series pair\n",
    "names = [\"GLI-ETH\", \"I0 GLI-ETH\", \"GLI-SPY\", \"I0 GLI-SPY\"]\n",
    "\n",
    "# Creating the DataFrame\n",
    "corr_df = create_correlation_dataframe([gli_eth_corr, i0_gli_eth_corr, gli_spy_corr, i0_gli_spy_corr], names)\n",
    "\n",
    "# Displaying the DataFrame\n",
    "corr_df.index.name = 'time_series_pairs'\n",
    "corr_df.reset_index(inplace=True)\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9a3029d-6277-435b-950b-9fe1c064b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.to_csv('eth_global-liquidity_corr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8479d5-9625-49b5-a182-879ec3174acd",
   "metadata": {},
   "source": [
    "## Cointegration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "776d45b5-7695-4111-a8d8-3128cd55c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def johansen_cointegration_test(ts1, ts2, confidence_level=0.05):\n",
    "    \"\"\"\n",
    "    Perform the Johansen cointegration test on two time series and provide an interpretation.\n",
    "\n",
    "    Parameters:\n",
    "    ts1 : Pandas Series\n",
    "        The first time series.\n",
    "    ts2 : Pandas Series\n",
    "        The second time series.\n",
    "    confidence_level : float\n",
    "        The confidence level for determining cointegration (default is 0.05).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Combine the series into a 2D array\n",
    "    ts_combined = np.column_stack([ts1, ts2])\n",
    "\n",
    "    # Perform the Johansen cointegration test\n",
    "    result = coint_johansen(ts_combined, det_order=0, k_ar_diff=1)\n",
    "\n",
    "    # The trace statistic and the maximum eigenvalue statistic\n",
    "    trace_stat = result.lr1\n",
    "    max_eig_stat = result.lr2\n",
    "\n",
    "    # Critical values at chosen confidence level (90%, 95%, 99%)\n",
    "    crit_val_index = {0.10: 0, 0.05: 1, 0.01: 2}[confidence_level]\n",
    "    trace_crit_vals = result.cvt[:, crit_val_index]\n",
    "    max_eig_crit_vals = result.cvm[:, crit_val_index]\n",
    "\n",
    "    # Print results and interpretation\n",
    "    print(\"Johansen Cointegration Test Results and Interpretation:\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    for idx, (trace, max_eig, trace_crit, max_eig_crit) in enumerate(zip(trace_stat, max_eig_stat, trace_crit_vals, max_eig_crit_vals)):\n",
    "        print(f\"Result for the Hypothesis of {idx} cointegrating relations:\")\n",
    "        print(f\"Trace Statistic: {trace:.2f}, Critical Value: {trace_crit:.2f}\")\n",
    "        print(f\"Max-Eigen Statistic: {max_eig:.2f}, Critical Value: {max_eig_crit:.2f}\")\n",
    "\n",
    "        if trace > trace_crit and max_eig > max_eig_crit:\n",
    "            print(\"Both Trace and Max-Eigen statistics are above the critical values, suggesting cointegration.\")\n",
    "        elif trace > trace_crit or max_eig > max_eig_crit:\n",
    "            print(\"One of the statistics is above the critical value, suggesting possible cointegration.\")\n",
    "        else:\n",
    "            print(\"Neither statistic is above the critical value, suggesting no cointegration.\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54f87d4f-3487-42bf-8379-28924869a237",
   "metadata": {},
   "outputs": [],
   "source": [
    "gli = df['Global_Liquidity_Index']\n",
    "eth = df['ETH-USD']\n",
    "spy = df['SPY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b900655-bf15-43d8-94af-6f97f5f07f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johansen Cointegration Test Results and Interpretation:\n",
      "-------------------------------------------------------\n",
      "Result for the Hypothesis of 0 cointegrating relations:\n",
      "Trace Statistic: 12.21, Critical Value: 15.49\n",
      "Max-Eigen Statistic: 11.27, Critical Value: 14.26\n",
      "Neither statistic is above the critical value, suggesting no cointegration.\n",
      "\n",
      "Result for the Hypothesis of 1 cointegrating relations:\n",
      "Trace Statistic: 0.94, Critical Value: 3.84\n",
      "Max-Eigen Statistic: 0.94, Critical Value: 3.84\n",
      "Neither statistic is above the critical value, suggesting no cointegration.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "johansen_cointegration_test(gli, eth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95e22e8d-79f3-43cc-8a33-5c54e41b1775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johansen Cointegration Test Results and Interpretation:\n",
      "-------------------------------------------------------\n",
      "Result for the Hypothesis of 0 cointegrating relations:\n",
      "Trace Statistic: 12.21, Critical Value: 15.49\n",
      "Max-Eigen Statistic: 11.27, Critical Value: 14.26\n",
      "Neither statistic is above the critical value, suggesting no cointegration.\n",
      "\n",
      "Result for the Hypothesis of 1 cointegrating relations:\n",
      "Trace Statistic: 0.94, Critical Value: 3.84\n",
      "Max-Eigen Statistic: 0.94, Critical Value: 3.84\n",
      "Neither statistic is above the critical value, suggesting no cointegration.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "johansen_cointegration_test(gli, eth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
