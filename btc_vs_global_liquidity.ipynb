{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0dd0164-5a4f-4264-9c14-800727b72537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yfinance # uncomment and run to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9a82c9d-79e2-46b1-9ade-da5efad49c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de9ee387-3c25-4e0d-b227-cbd6b8d00b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = \"1d\"\n",
    "start_time = \"2018-01-01\"\n",
    "end_time = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')  # Set end_time to yesterday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22b191-afa6-4b08-b0e8-0f76cf33e520",
   "metadata": {},
   "source": [
    "1. **TLT (iShares 20+ Year Treasury Bond ETF)**: Invests in U.S. Treasury bonds with remaining maturities greater than 20 years, aiming to track the investment results of an index composed of U.S. Treasury bonds.\n",
    "\n",
    "2. **IEF (iShares 7-10 Year Treasury Bond ETF)**: Seeks to track the investment results of an index composed of U.S. Treasury bonds with remaining maturities between 7 and 10 years.\n",
    "\n",
    "3. **EZU (iShares MSCI Eurozone ETF)**: Provides exposure to large and mid-sized companies in Eurozone countries, tracking the MSCI EMU Index.\n",
    "\n",
    "4. **CNYA (iShares MSCI China A ETF)**: Offers exposure to large and mid-cap Chinese equities in the A-shares market, tracking the MSCI China A Inclusion Index.\n",
    "\n",
    "5. **EWJ (iShares MSCI Japan ETF)**: Tracks the investment results of an index composed of Japanese equities, representing large and mid-sized companies in Japan.\n",
    "\n",
    "6. **IGLT.L (iShares Core UK Gilts UCITS ETF)**: Invests in UK government bonds (gilts), seeking to track the performance of an index composed of sterling-denominated UK government bonds.\n",
    "\n",
    "7. **XBB.TO (iShares Core Canadian Universe Bond Index ETF)**: Offers exposure to Canadian government and corporate bonds, tracking the performance of the broad Canadian bond market.\n",
    "\n",
    "8. **BOND.AX (PIMCO Australian Bond Index Fund)**: Provides diversified exposure to the Australian bond market, including government, semi-government, and corporate debt securities.\n",
    "\n",
    "9. **INDA (iShares MSCI India ETF)**: Aims to track the investment results of an index composed of Indian equities, representing large and mid-sized companies in India.\n",
    "\n",
    "10. **EWL (iShares MSCI Switzerland ETF)**: Tracks the investment results of an index composed of Swiss equities, representing the Swiss stock market.\n",
    "\n",
    "11. **ERUS (iShares MSCI Russia ETF)**: Seeks to track the investment results of an index composed of Russian equities.\n",
    "\n",
    "12. **EWZ (iShares MSCI Brazil ETF)**: Aims to track the investment results of an index composed of Brazilian equities, reflecting the performance of the Brazilian stock market.\n",
    "\n",
    "13. **EWY (iShares MSCI South Korea ETF)**: Tracks the investment results of an index composed of South Korean equities, representing the South Korean stock market.\n",
    "\n",
    "14. **ENZL (iShares MSCI New Zealand ETF)**: Seeks to track the investment results of an index composed of New Zealand equities.\n",
    "\n",
    "15. **EWD (iShares MSCI Sweden ETF)**: Aims to track the investment results of an index composed of Swedish equities, representing the Swedish stock market.\n",
    "\n",
    "16. **EWM (iShares MSCI Malaysia ETF)**: Seeks to track the investment results of an index composed of Malaysian equities, representing the Malaysian stock market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4b3632-bd34-4c71-a64f-dfa778d07b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TLT': 0.38885760822225623, 'IEF': 0.23733374117905118, 'EZU': 0.05512229582981665, 'CNYA': 0.0018691532124829246, 'EWJ': 0.11149735828661055, 'IGLT.L': 0.0, 'XBB.TO': 0.05474578961840785, 'BOND.AX': 0.00031229276775030873, 'INDA': 0.05383947242196183, 'EWL': 0.010350169684085225, 'ERUS': 4.502729743237624e-05, 'EWZ': 0.047789691310546986, 'EWY': 0.03259198028276192, 'ENZL': 0.000986829085515959, 'EWD': 0.002654322728686626, 'EWM': 0.002004268072633402}\n"
     ]
    }
   ],
   "source": [
    "# Define ETFs\n",
    "etfs = [\"TLT\", \"IEF\", \"EZU\", \"CNYA\", \"EWJ\", \"IGLT.L\", \"XBB.TO\", \"BOND.AX\", \"INDA\", \"EWL\", \"ERUS\", \"EWZ\", \"EWY\", \"ENZL\", \"EWD\", \"EWM\"]\n",
    "\n",
    "# Fetch ETF data\n",
    "etf_data = {etf: yf.Ticker(etf).info for etf in etfs}\n",
    "\n",
    "# Retrieve AUM or market cap\n",
    "aum = {etf: data.get('totalAssets', 0) for etf, data in etf_data.items()}  \n",
    "\n",
    "# Calculate total AUM\n",
    "total_aum = sum(aum.values())\n",
    "\n",
    "# Calculate weightings\n",
    "weights = {etf: value / total_aum for etf, value in aum.items()}\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad21236-0277-4f8b-8491-9acfb4ae8fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "NaN count per column:\n",
      " ^IRX                       0\n",
      "^TNX                       0\n",
      "^TYX                       0\n",
      "SPY                        0\n",
      "QQQ                        0\n",
      "TLT                        0\n",
      "IEF                        0\n",
      "EZU                        0\n",
      "CNYA                       0\n",
      "EWJ                        0\n",
      "IGLT.L                    30\n",
      "XBB.TO                    32\n",
      "BOND.AX                   31\n",
      "INDA                       0\n",
      "EWL                        0\n",
      "ERUS                       0\n",
      "EWZ                        0\n",
      "EWY                        0\n",
      "ENZL                       0\n",
      "EWD                        0\n",
      "EWM                        0\n",
      "BTC-USD                    0\n",
      "Global_Liquidity_Index     0\n",
      "dtype: int64\n",
      "Total NaN values in the DataFrame: 93\n"
     ]
    }
   ],
   "source": [
    "# Existing tickers and ETF tickers (& BTC, ETH in USD)\n",
    "tickers = [\"^IRX\", \"^TNX\", \"^TYX\", \"SPY\", \"QQQ\"]\n",
    "etf_tickers = etfs  \n",
    "tickers.extend(etf_tickers)\n",
    "crypto_tickers = ['BTC-USD']\n",
    "tickers.extend(crypto_tickers)\n",
    "\n",
    "# Retrieve historical data\n",
    "historical_data = {}\n",
    "for ticker in tickers:\n",
    "    historical_data[ticker] = yf.download(ticker, start=start_time, end=end_time, interval=frequency)['Close']\n",
    "\n",
    "# Combine and weight data\n",
    "combined_data = pd.DataFrame()\n",
    "for ticker, data in historical_data.items():\n",
    "    if ticker in weights:  # Check if ticker is in ETFs list\n",
    "        combined_data[ticker] = data * weights[ticker]\n",
    "    else:  # Use the data as is for other tickers\n",
    "        combined_data[ticker] = data\n",
    "\n",
    "# Calculate the Global Liquidity Index as the sum of all (weighted and non-weighted) columns, excluding crypto tickers\n",
    "combined_data['Global_Liquidity_Index'] = combined_data.drop(columns=crypto_tickers, errors='ignore').sum(axis=1)\n",
    "\n",
    "# Count NaN values in each column\n",
    "nan_count_per_column = combined_data.isna().sum()\n",
    "print(\"NaN count per column:\\n\", nan_count_per_column)\n",
    "\n",
    "# Total NaN values in the DataFrame\n",
    "total_nan_count = combined_data.isna().sum().sum()\n",
    "print(\"Total NaN values in the DataFrame:\", total_nan_count)\n",
    "\n",
    "combined_data.dropna(inplace=True)\n",
    "\n",
    "# combined_data now contains the weighted Global Liquidity Index and individual ticker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65dfa516-23c0-4d6f-a77c-e7a3549f2330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_Liquidity_Index</th>\n",
       "      <th>SPY</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>GLI_diff</th>\n",
       "      <th>SPY_diff</th>\n",
       "      <th>BTC_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>529.168215</td>\n",
       "      <td>270.470001</td>\n",
       "      <td>15201.000000</td>\n",
       "      <td>3.613578</td>\n",
       "      <td>1.700012</td>\n",
       "      <td>218.900391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>530.703634</td>\n",
       "      <td>271.609985</td>\n",
       "      <td>15599.200195</td>\n",
       "      <td>1.535419</td>\n",
       "      <td>1.139984</td>\n",
       "      <td>398.200195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>534.124869</td>\n",
       "      <td>273.420013</td>\n",
       "      <td>17429.500000</td>\n",
       "      <td>3.421235</td>\n",
       "      <td>1.810028</td>\n",
       "      <td>1830.299805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>535.250383</td>\n",
       "      <td>273.920013</td>\n",
       "      <td>15170.099609</td>\n",
       "      <td>1.125514</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-2259.400391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>535.259241</td>\n",
       "      <td>274.540009</td>\n",
       "      <td>14595.400391</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>0.619995</td>\n",
       "      <td>-574.699219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22</th>\n",
       "      <td>974.601569</td>\n",
       "      <td>473.649994</td>\n",
       "      <td>43997.902344</td>\n",
       "      <td>1.416192</td>\n",
       "      <td>0.949982</td>\n",
       "      <td>128.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>981.543728</td>\n",
       "      <td>476.510010</td>\n",
       "      <td>43442.855469</td>\n",
       "      <td>6.942159</td>\n",
       "      <td>2.860016</td>\n",
       "      <td>-555.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>981.290662</td>\n",
       "      <td>476.690002</td>\n",
       "      <td>42627.855469</td>\n",
       "      <td>-0.253066</td>\n",
       "      <td>0.179993</td>\n",
       "      <td>-815.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>977.718755</td>\n",
       "      <td>475.309998</td>\n",
       "      <td>42099.402344</td>\n",
       "      <td>-3.571906</td>\n",
       "      <td>-1.380005</td>\n",
       "      <td>-528.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>967.820938</td>\n",
       "      <td>472.649994</td>\n",
       "      <td>44957.968750</td>\n",
       "      <td>-9.897817</td>\n",
       "      <td>-2.660004</td>\n",
       "      <td>2858.566406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1438 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Global_Liquidity_Index         SPY       BTC-USD  GLI_diff  \\\n",
       "Date                                                                     \n",
       "2018-01-03              529.168215  270.470001  15201.000000  3.613578   \n",
       "2018-01-04              530.703634  271.609985  15599.200195  1.535419   \n",
       "2018-01-05              534.124869  273.420013  17429.500000  3.421235   \n",
       "2018-01-08              535.250383  273.920013  15170.099609  1.125514   \n",
       "2018-01-09              535.259241  274.540009  14595.400391  0.008857   \n",
       "...                            ...         ...           ...       ...   \n",
       "2023-12-22              974.601569  473.649994  43997.902344  1.416192   \n",
       "2023-12-27              981.543728  476.510010  43442.855469  6.942159   \n",
       "2023-12-28              981.290662  476.690002  42627.855469 -0.253066   \n",
       "2023-12-29              977.718755  475.309998  42099.402344 -3.571906   \n",
       "2024-01-02              967.820938  472.649994  44957.968750 -9.897817   \n",
       "\n",
       "            SPY_diff     BTC_diff  \n",
       "Date                               \n",
       "2018-01-03  1.700012   218.900391  \n",
       "2018-01-04  1.139984   398.200195  \n",
       "2018-01-05  1.810028  1830.299805  \n",
       "2018-01-08  0.500000 -2259.400391  \n",
       "2018-01-09  0.619995  -574.699219  \n",
       "...              ...          ...  \n",
       "2023-12-22  0.949982   128.750000  \n",
       "2023-12-27  2.860016  -555.046875  \n",
       "2023-12-28  0.179993  -815.000000  \n",
       "2023-12-29 -1.380005  -528.453125  \n",
       "2024-01-02 -2.660004  2858.566406  \n",
       "\n",
       "[1438 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = combined_data[['Global_Liquidity_Index', 'SPY', 'BTC-USD']].copy() # truncate df for dune upload\n",
    "\n",
    "# Calculate the first difference for the specified columns\n",
    "df['GLI_diff'] = df['Global_Liquidity_Index'].diff()\n",
    "df['SPY_diff'] = df['SPY'].diff()\n",
    "df['BTC_diff'] = df['BTC-USD'].diff()\n",
    "\n",
    "df.dropna(inplace=True) # drop missing value from first differencing  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "166b9ab0-19e8-4a46-bd88-2cfb453585e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('btc_global_liquidity_index.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ea35ce8-a491-42dd-9d50-0d1a7ade5396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for stationarity in series: Global_Liquidity_Index\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'adfuller' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pr/7pc2lrys2kb2zyndq0js_rx40000gn/T/ipykernel_67619/1711642292.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Perform Augmented Dickey-Fuller test:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Testing for stationarity in series: {column}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madfuller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# dropna() handles missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ADF Statistic: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p-value: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adfuller' is not defined"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    # Perform Augmented Dickey-Fuller test:\n",
    "    print(f'Testing for stationarity in series: {column}')\n",
    "    result = adfuller(df[column].dropna())  # dropna() handles missing values\n",
    "    print('ADF Statistic: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "    # Interpretation\n",
    "    if result[1] > 0.05:\n",
    "        print(f\"The series {column} is likely non-stationary (fail to reject H0)\\n\")\n",
    "        print(\"___________________________________________________________________\")\n",
    "    else:\n",
    "        print(f\"The series {column} is likely stationary (reject H0)\\n\")\n",
    "        print(\"___________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b74e1-6366-44c2-9601-3393be9a8972",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc = df['BTC-USD']\n",
    "gli = df['Global_Liquidity_Index']  \n",
    "spy = df['SPY'] # benchmark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f8c972-2284-4ad1-b92a-e2549e79f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "\n",
    "def johansen_cointegration_test(ts1, ts2):\n",
    "    \"\"\"\n",
    "    Perform the Johansen cointegration test on two time series.\n",
    "\n",
    "    Parameters:\n",
    "    ts1 : Pandas Series\n",
    "        The first time series.\n",
    "    ts2 : Pandas Series\n",
    "        The second time series.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Combine the series into a 2D array\n",
    "    ts_combined = np.column_stack([ts1, ts2])\n",
    "\n",
    "    # Perform the Johansen cointegration test\n",
    "    result = coint_johansen(ts_combined, det_order=0, k_ar_diff=1)\n",
    "\n",
    "    # The trace statistic and the maximum eigenvalue statistic\n",
    "    trace_stat = result.lr1\n",
    "    max_eig_stat = result.lr2\n",
    "\n",
    "    # Critical values at 90%, 95%, and 99% confidence intervals\n",
    "    trace_crit_vals = result.cvt\n",
    "    max_eig_crit_vals = result.cvm\n",
    "\n",
    "    # Print results\n",
    "    print(\"Johansen Cointegration Test Results:\")\n",
    "    print(\"------------------------------------\")\n",
    "    for idx, (trace, max_eig, trace_crit, max_eig_crit) in enumerate(zip(trace_stat, max_eig_stat, trace_crit_vals, max_eig_crit_vals)):\n",
    "        print(f\"Result for the Hypothesis of {idx} cointegrating relations:\")\n",
    "        print(f\"Trace Statistic: {trace:.2f}, Critical Values (90%, 95%, 99%): {trace_crit}\")\n",
    "        print(f\"Max-Eigen Statistic: {max_eig:.2f}, Critical Values (90%, 95%, 99%): {max_eig_crit}\")\n",
    "        print(\"\")\n",
    "\n",
    "    # Interpretation of the test\n",
    "    print(\"Interpretation:\")\n",
    "    print(\"---------------\")\n",
    "    print(\"If the Trace and/or Max-Eigen statistics are greater than the 95% critical values, the null\")\n",
    "    print(\"hypothesis of 'no cointegration' is rejected, indicating cointegration relations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a5eb91-d3a3-4b39-b6ce-a05ec7959c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "\n",
    "def johansen_cointegration_test(ts1, ts2, confidence_level=0.05):\n",
    "    \"\"\"\n",
    "    Perform the Johansen cointegration test on two time series and provide an interpretation.\n",
    "\n",
    "    Parameters:\n",
    "    ts1 : Pandas Series\n",
    "        The first time series.\n",
    "    ts2 : Pandas Series\n",
    "        The second time series.\n",
    "    confidence_level : float\n",
    "        The confidence level for determining cointegration (default is 0.05).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Combine the series into a 2D array\n",
    "    ts_combined = np.column_stack([ts1, ts2])\n",
    "\n",
    "    # Perform the Johansen cointegration test\n",
    "    result = coint_johansen(ts_combined, det_order=0, k_ar_diff=1)\n",
    "\n",
    "    # The trace statistic and the maximum eigenvalue statistic\n",
    "    trace_stat = result.lr1\n",
    "    max_eig_stat = result.lr2\n",
    "\n",
    "    # Critical values at chosen confidence level (90%, 95%, 99%)\n",
    "    crit_val_index = {0.10: 0, 0.05: 1, 0.01: 2}[confidence_level]\n",
    "    trace_crit_vals = result.cvt[:, crit_val_index]\n",
    "    max_eig_crit_vals = result.cvm[:, crit_val_index]\n",
    "\n",
    "    # Print results and interpretation\n",
    "    print(\"Johansen Cointegration Test Results and Interpretation:\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    for idx, (trace, max_eig, trace_crit, max_eig_crit) in enumerate(zip(trace_stat, max_eig_stat, trace_crit_vals, max_eig_crit_vals)):\n",
    "        print(f\"Result for the Hypothesis of {idx} cointegrating relations:\")\n",
    "        print(f\"Trace Statistic: {trace:.2f}, Critical Value: {trace_crit:.2f}\")\n",
    "        print(f\"Max-Eigen Statistic: {max_eig:.2f}, Critical Value: {max_eig_crit:.2f}\")\n",
    "\n",
    "        if trace > trace_crit and max_eig > max_eig_crit:\n",
    "            print(\"Both Trace and Max-Eigen statistics are above the critical values, suggesting cointegration.\")\n",
    "        elif trace > trace_crit or max_eig > max_eig_crit:\n",
    "            print(\"One of the statistics is above the critical value, suggesting possible cointegration.\")\n",
    "        else:\n",
    "            print(\"Neither statistic is above the critical value, suggesting no cointegration.\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b59039-3856-46a7-b3a5-5020d7d551fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca9ac7f6-5cd0-472e-8b5f-333b66b8207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7f77693-cd6b-4fa2-bacb-11cc7425a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlations(ts1, ts2):\n",
    "    \"\"\"\n",
    "    Calculate the Pearson, Spearman, and Kendall Tau correlation coefficients along with their p-values for two time series.\n",
    "\n",
    "    Parameters:\n",
    "    ts1 : Pandas Series\n",
    "        The first time series.\n",
    "    ts2 : Pandas Series\n",
    "        The second time series.\n",
    "\n",
    "    Returns:\n",
    "    dict\n",
    "        A dictionary containing the Pearson, Spearman, and Kendall Tau correlation coefficients and their p-values.\n",
    "    \"\"\"\n",
    "    pearson_corr, pearson_p = pearsonr(ts1, ts2)\n",
    "    spearman_corr, spearman_p = spearmanr(ts1, ts2)\n",
    "    kendall_corr, kendall_p = kendalltau(ts1, ts2)\n",
    "\n",
    "    return {\n",
    "        'Pearson': {'Coefficient': pearson_corr, 'P-Value': pearson_p},\n",
    "        'Spearman': {'Coefficient': spearman_corr, 'P-Value': spearman_p},\n",
    "        'Kendall Tau': {'Coefficient': kendall_corr, 'P-Value': kendall_p}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb23b3cb-54e0-419f-b4b3-65fba1238f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pearson': {'Coefficient': 0.8693334622326608, 'P-Value': 0.0},\n",
       " 'Spearman': {'Coefficient': 0.9109390889880306, 'P-Value': 0.0},\n",
       " 'Kendall Tau': {'Coefficient': 0.733494160147782, 'P-Value': 0.0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gli_btc_corr = calculate_correlations(corr_df['Global_Liquidity_Index'], corr_df['BTC-USD'])\n",
    "gli_btc_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71618081-903c-49d1-b96f-3355d0393219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pearson': {'Coefficient': 0.2707416127256846,\n",
       "  'P-Value': 1.4091913565896897e-25},\n",
       " 'Spearman': {'Coefficient': 0.2642358484218297,\n",
       "  'P-Value': 2.129460142036639e-24},\n",
       " 'Kendall Tau': {'Coefficient': 0.1813681248351818,\n",
       "  'P-Value': 6.763503970929212e-25}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1_gli_btc_corr = calculate_correlations(corr_df['GLI_diff'], corr_df['BTC_diff'])\n",
    "i1_gli_btc_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0ecc719-3eae-43ec-9c37-5a21d6802523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pearson': {'Coefficient': 0.989583982577496, 'P-Value': 0.0},\n",
       " 'Spearman': {'Coefficient': 0.9896298891645711, 'P-Value': 0.0},\n",
       " 'Kendall Tau': {'Coefficient': 0.9232025995935197, 'P-Value': 0.0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gli_spy_corr = calculate_correlations(corr_df['Global_Liquidity_Index'], corr_df['SPY'])\n",
    "gli_spy_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "492655af-a1d8-4efb-9d71-fe7413dc871a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pearson': {'Coefficient': 0.9764064383179702, 'P-Value': 0.0},\n",
       " 'Spearman': {'Coefficient': 0.9707538911082162, 'P-Value': 0.0},\n",
       " 'Kendall Tau': {'Coefficient': 0.8633657607478469, 'P-Value': 0.0}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1_gli_spy_corr = calculate_correlations(corr_df['GLI_diff'], corr_df['SPY_diff'])\n",
    "i1_gli_spy_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a799887-2ecc-4903-b913-a3ed00f10295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_series_pairs</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Spearman</th>\n",
       "      <th>Kendall Tau</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GLI-BTC</td>\n",
       "      <td>0.869333</td>\n",
       "      <td>0.910939</td>\n",
       "      <td>0.733494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I1-GLI-BTC</td>\n",
       "      <td>0.270742</td>\n",
       "      <td>0.264236</td>\n",
       "      <td>0.181368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GLI-SPY</td>\n",
       "      <td>0.989584</td>\n",
       "      <td>0.989630</td>\n",
       "      <td>0.923203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I1-GLI-SPY</td>\n",
       "      <td>0.976406</td>\n",
       "      <td>0.970754</td>\n",
       "      <td>0.863366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  time_series_pairs   Pearson  Spearman  Kendall Tau\n",
       "0           GLI-BTC  0.869333  0.910939     0.733494\n",
       "1        I1-GLI-BTC  0.270742  0.264236     0.181368\n",
       "2           GLI-SPY  0.989584  0.989630     0.923203\n",
       "3        I1-GLI-SPY  0.976406  0.970754     0.863366"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_correlation_dataframe(dicts, names):\n",
    "    \"\"\"\n",
    "    Create a pandas DataFrame from a list of dictionaries containing correlation coefficients, with named rows.\n",
    "\n",
    "    Parameters:\n",
    "    dicts : list of dict\n",
    "        List of dictionaries with correlation data.\n",
    "    names : list of str\n",
    "        List of names for each time series pair.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame\n",
    "        A DataFrame with correlation coefficients and named rows.\n",
    "    \"\"\"\n",
    "    # Prepare data for DataFrame\n",
    "    data = {name: {metric: d[metric]['Coefficient'] for metric in ['Pearson', 'Spearman', 'Kendall Tau']} for name, d in zip(names, dicts)}\n",
    "\n",
    "    # Create DataFrame from the data\n",
    "    corr_df = pd.DataFrame(data).T\n",
    "\n",
    "    return corr_df\n",
    "\n",
    "# Names for each time series pair\n",
    "names = [\"GLI-BTC\", \"I1-GLI-BTC\", \"GLI-SPY\", \"I1-GLI-SPY\"]\n",
    "\n",
    "# Creating the DataFrame\n",
    "corr_df = create_correlation_dataframe([gli_btc_corr, i1_gli_btc_corr, gli_spy_corr, i1_gli_spy_corr], names)\n",
    "\n",
    "# Displaying the DataFrame\n",
    "corr_df.index.name = 'time_series_pairs'\n",
    "corr_df.reset_index(inplace=True)\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9a3029d-6277-435b-950b-9fe1c064b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.to_csv('btc_global-liquidity_corr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8479d5-9625-49b5-a182-879ec3174acd",
   "metadata": {},
   "source": [
    "# Cointegration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "776d45b5-7695-4111-a8d8-3128cd55c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def johansen_cointegration_test(ts1, ts2, confidence_level=0.05):\n",
    "    \"\"\"\n",
    "    Perform the Johansen cointegration test on two time series and provide an interpretation.\n",
    "\n",
    "    Parameters:\n",
    "    ts1 : Pandas Series\n",
    "        The first time series.\n",
    "    ts2 : Pandas Series\n",
    "        The second time series.\n",
    "    confidence_level : float\n",
    "        The confidence level for determining cointegration (default is 0.05).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Combine the series into a 2D array\n",
    "    ts_combined = np.column_stack([ts1, ts2])\n",
    "\n",
    "    # Perform the Johansen cointegration test\n",
    "    result = coint_johansen(ts_combined, det_order=0, k_ar_diff=1)\n",
    "\n",
    "    # The trace statistic and the maximum eigenvalue statistic\n",
    "    trace_stat = result.lr1\n",
    "    max_eig_stat = result.lr2\n",
    "\n",
    "    # Critical values at chosen confidence level (90%, 95%, 99%)\n",
    "    crit_val_index = {0.10: 0, 0.05: 1, 0.01: 2}[confidence_level]\n",
    "    trace_crit_vals = result.cvt[:, crit_val_index]\n",
    "    max_eig_crit_vals = result.cvm[:, crit_val_index]\n",
    "\n",
    "    # Print results and interpretation\n",
    "    print(\"Johansen Cointegration Test Results and Interpretation:\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    for idx, (trace, max_eig, trace_crit, max_eig_crit) in enumerate(zip(trace_stat, max_eig_stat, trace_crit_vals, max_eig_crit_vals)):\n",
    "        print(f\"Result for the Hypothesis of {idx} cointegrating relations:\")\n",
    "        print(f\"Trace Statistic: {trace:.2f}, Critical Value: {trace_crit:.2f}\")\n",
    "        print(f\"Max-Eigen Statistic: {max_eig:.2f}, Critical Value: {max_eig_crit:.2f}\")\n",
    "\n",
    "        if trace > trace_crit and max_eig > max_eig_crit:\n",
    "            print(\"Both Trace and Max-Eigen statistics are above the critical values, suggesting cointegration.\")\n",
    "        elif trace > trace_crit or max_eig > max_eig_crit:\n",
    "            print(\"One of the statistics is above the critical value, suggesting possible cointegration.\")\n",
    "        else:\n",
    "            print(\"Neither statistic is above the critical value, suggesting no cointegration.\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54f87d4f-3487-42bf-8379-28924869a237",
   "metadata": {},
   "outputs": [],
   "source": [
    "gli = df['Global_Liquidity_Index']\n",
    "btc = df['BTC-USD']\n",
    "spy = df['SPY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b900655-bf15-43d8-94af-6f97f5f07f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johansen Cointegration Test Results and Interpretation:\n",
      "-------------------------------------------------------\n",
      "Result for the Hypothesis of 0 cointegrating relations:\n",
      "Trace Statistic: 10.25, Critical Value: 15.49\n",
      "Max-Eigen Statistic: 9.91, Critical Value: 14.26\n",
      "Neither statistic is above the critical value, suggesting no cointegration.\n",
      "\n",
      "Result for the Hypothesis of 1 cointegrating relations:\n",
      "Trace Statistic: 0.34, Critical Value: 3.84\n",
      "Max-Eigen Statistic: 0.34, Critical Value: 3.84\n",
      "Neither statistic is above the critical value, suggesting no cointegration.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "johansen_cointegration_test(gli, btc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95e22e8d-79f3-43cc-8a33-5c54e41b1775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johansen Cointegration Test Results and Interpretation:\n",
      "-------------------------------------------------------\n",
      "Result for the Hypothesis of 0 cointegrating relations:\n",
      "Trace Statistic: 9.13, Critical Value: 15.49\n",
      "Max-Eigen Statistic: 6.85, Critical Value: 14.26\n",
      "Neither statistic is above the critical value, suggesting no cointegration.\n",
      "\n",
      "Result for the Hypothesis of 1 cointegrating relations:\n",
      "Trace Statistic: 2.29, Critical Value: 3.84\n",
      "Max-Eigen Statistic: 2.29, Critical Value: 3.84\n",
      "Neither statistic is above the critical value, suggesting no cointegration.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "johansen_cointegration_test(gli, spy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
